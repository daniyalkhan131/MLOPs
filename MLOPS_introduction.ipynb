{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "KHX2QtP5CL4q"
   },
   "outputs": [],
   "source": [
    "#data is key to machine learning, openAI invest millions of money on data collectn sourcing synthesis, than on\n",
    "#model building\n",
    "\n",
    "#data       data engineering      modeling      operationalizing\n",
    "\n",
    "#model need to come out from notebook in form of pyspark, scala or python script\n",
    "\n",
    "#in operationalizing we first do registration before deployment because model need to be registered on a node so that\n",
    "#client can access that\n",
    "#registration is also called version control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "UHuEaDU6KERB"
   },
   "outputs": [],
   "source": [
    "#we need to have debugging nature to resolve installing of things, things not working out so need to have that skill\n",
    "#of resolving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "NIindqjQKhYE"
   },
   "outputs": [],
   "source": [
    "#data ingest- getting data from sql, query engine, etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "sR4JIA-QK98D"
   },
   "outputs": [],
   "source": [
    "#MLOPs comes from DevOPs\n",
    "#writing code comes under software development and deploying that managaing that, deriving values all these things\n",
    "#handling comes in DevOPs\n",
    "\n",
    "#but in ML logic is not the only thing but the data also, and our apps that are deployed getting a lot of data\n",
    "# so we need to know distributed app concept the cloud working\n",
    "\n",
    "#MLOPs is actually marraing developers operation and this machine learning lifecycle\n",
    "#for MLOPs understanding machine learning, models is must\n",
    "\n",
    "#in MLOPs we have code data and model and together all three we have to do maintainence deployment and monitoring"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "Z5a4BsQQMRoP"
   },
   "outputs": [],
   "source": [
    "#if a person know about ML and infrastructure like sql, data pipeline through scala, distributed way working so he is\n",
    "# data platform engineer\n",
    "#and if know ML and software engineering then ml engineering\n",
    "#and all three together is MLOPs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "twizl4IwO6pJ"
   },
   "outputs": [],
   "source": [
    "#version control is basically saving your work\n",
    "#we make node then if make changes to that then new node created and if we want to go back to previous without change one\n",
    "#then can go there to privious version\n",
    "#version control has advantage in collaborated working\n",
    "\n",
    "#git is developed that is actual service and on that github is made, bitbucket, AWS commit, etc\n",
    "#we have functionality of branching in this where many people working on same thing diffferently then after that\n",
    "#merging is done\n",
    "\n",
    "#documentation is must because when we move from one version to other than have to specify in a good and understanding manner\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "-57TSGI2TbX5"
   },
   "outputs": [],
   "source": [
    "#git is DVCS, distributed type of version control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "lC-CaUaaTfs5"
   },
   "outputs": [],
   "source": [
    "#In Python, you can use the popular pandas library to load and manipulate your data.\n",
    "#NOTE - It will be great if you practice with Dask and Polars along with Pandas, both these libraries extend\n",
    "#pandas to handle distributed filesystem making it less memory dependent while offering similar usability at scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sometimes we have to deal with data that is coming in streams so we have to deal with that also"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The model deployment process can be summarized as follows:\n",
    "\n",
    "#Environment Setup: Create a production environment suitable for running the model. \n",
    "#This may involve setting up servers, cloud infrastructure, or edge devices.\n",
    "\n",
    "#Model Packaging: Prepare the model for deployment by saving its architecture, weights, and preprocessing steps.\n",
    "\n",
    "#Scalability: Consider the scalability of the deployed model to handle varying workloads and user demand. \n",
    "#This may involve deploying multiple instances of the model or using load balancing.\n",
    "\n",
    "#Monitoring: Implement a monitoring system to keep an eye on the model's performance. Detect model drift, \n",
    "#changes in data distribution, and any decrease in prediction accuracy.\n",
    "\n",
    "#Feedback Loop: Create a feedback loop to collect user feedback and actual outcomes. This information \n",
    "#can be used to retrain the model and improve its performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we cam create repo on github using git also from command line\n",
    "#for that we use git init and then push that to github\n",
    "\n",
    "#we can clone repo from github using https or ssh from code button\n",
    "# git clone enter url\n",
    "\n",
    "#git status - it is for chezking what changes made in the local repo\n",
    "# git add . -it is for telling git to get ready to upload things specifed to cloud and . for all changes upload to cloud\n",
    "#now after that write git status will show green color changes that means it is ready with changes\n",
    "#and before adding to cloud we need to commit changes so we do git commit -m 'message'\n",
    "#now we have to send this to cloud so can see changes in the github\n",
    "#for this command is- git push origin main \n",
    "#main is my branch name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we create branch so that without making changes in main branch we make changes in branch\n",
    "#and then request for merging that to original, and if the originator or main person want than he can accept the request\n",
    "\n",
    "# branch create- git branch branchname\n",
    "#now switch to that branch by typinh- git checkout branchname\n",
    "#then add features there then add,commit,and push but this time do- git push origin branchname\n",
    "\n",
    "\n",
    "#we use this like creating feature for a software then can add feature in branch and test that software and then merge that\n",
    "#changes or code working fine\n",
    "\n",
    "#the branch holder friend send pull request to main for merging to we can also add rule that atleast 3 people should \n",
    "#review that then that will be added to main file and we merge by seeing the differences and then deciding by\n",
    "#writing full discription of changes and additions\n",
    "#then we can delete or not the branch \n",
    "\n",
    "#but these things are done on cloud so we need to do things on local beacuse in local we are in branch\n",
    "#we do git branch then see branch which we create, and if start doing something on this than this will be the branch\n",
    "#created, so we need to intentionally tell that this branch work is done so close this\n",
    "#so write git checkout main\n",
    "#then do git pull to update the local branch as in cloud things are updated and branch deleted\n",
    "#now we can see branch we have testbranch in local so we can delete that"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#never push dataset, passwords in the github, there is a way to do that so that things remain private"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#we do data science things using functions, like reading data, then preprocessing, then model bulding , tuning etc\n",
    "#and we create pipeline of this so they are in connection with each other, this is correct way of doing in industry\n",
    "#and define all things with proper comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from data preprocessing to model evaluation we call that pipeline in ML, so all these will run together and work together\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#weights and biases is monitoring platform for model, bascically monitoring the loss change in weights, etc etc\n",
    "#big models trained are monitored using this\n",
    "\n",
    "#most fresh ready to use data for ML models is bascically called features store, where we have ready to use features,\n",
    "#feast and techton are for this, many models can take data from this central locatn as in company we do different\n",
    "#modeling on same data or with some slight additional data\n",
    "\n",
    "#Beam provides support for running model evaluation on a TensorFlow model directly inside your pipeline. \n",
    "#The ML model evaluation page shows how to integrate model evaluation as part of your pipeline by using \n",
    "#TensorFlow Model Analysis (TFMA)\n",
    "\n",
    "#zenML is platform that give end to end MLOPs, it combine all the tools required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#if you have skill to do all these MLOPs lifecycle in AWS services, what tools in that to use when n how then companies\n",
    "#will want you\n",
    "#AWS has 250 services"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#every industry has different tool to work\n",
    "#docker, Hashicorp, kubernates, asana, atlasian, github, supabase, spinnaker, armory, datadog, splunk, grafana labs, \n",
    "#kibana, sentry, traccable, semgrep, raycast, auth0, retool, hackernews, medium"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
